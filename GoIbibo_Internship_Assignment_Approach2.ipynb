{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOIBIBO INTERNSHIP ASSIGNEMNT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:-\n",
    "\n",
    "1) In this notebook, I have used **Count Vectorizer** to get the counts of all the words.\n",
    "\n",
    "2) In the Count Vectorizer only I have removed the English **stop words**.\n",
    "\n",
    "3) Also at last, I have displayed **top ten** words again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IO1tYxRYE3Hq",
    "outputId": "b3f76e85-725f-4f2f-d7aa-994bf81ad127"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('all',halt_on_error=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "rwQIOULZRwD_",
    "outputId": "1c3131e7-d30c-412e-8e22-ea0b063ba15f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "% matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#nltk\n",
    "import nltk\n",
    "\n",
    "#preprocessing\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer  # using the Porter Stemmer and Lancaster Stemmer and others\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "\n",
    "# for part-of-speech tagging\n",
    "from nltk import pos_tag\n",
    "\n",
    "# for named entity recognition (NER)\n",
    "from nltk import ne_chunk\n",
    "\n",
    "# vectorizers for creating the document-term-matrix (DTM)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "# BeautifulSoup libraray\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "import re # regex\n",
    "\n",
    "#model_selection\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#evaluation\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score \n",
    "from sklearn.metrics import classification_report\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "#preprocessing scikit\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder\n",
    "\n",
    "#classifiaction.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    " \n",
    "#stop-words\n",
    "stop_words=set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "#keras\n",
    "import keras\n",
    "from keras.preprocessing.text import one_hot,Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Flatten ,Embedding,Input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "#gensim w2v\n",
    "#word2vec\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READING THE TEXT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fzkq4EG9TiVP"
   },
   "outputs": [],
   "source": [
    "f=open(\"drive/big.txt\")\n",
    "raw_text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING THE COUNT VECTORIZER TO GET THE COUNT OF WORDS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part I have used the Count Vectorizer availabe in scikit whihch can be used to count the number of words. Also I have this time used the **stop words** list by NLTK only to remove the **stop words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9HtTwLWUxRV"
   },
   "outputs": [],
   "source": [
    "l=[raw_text]\n",
    "vect_count=CountVectorizer(max_features=15000,min_df=1,ngram_range=(1,1),stop_words='english')# can play with aparamemters.\n",
    "text_count=vect_count.fit_transform(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives the vocabulary of the vectorizer. Note that the number in front of the word is the index of the word in the learnt vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QE8_8WdQZ9E3",
    "outputId": "8a9bed0c-bec0-46bc-c5eb-73923d167cfc"
   },
   "outputs": [],
   "source": [
    "vect_count.vocabulary_  # displays the learnt vocabulary. Commented out because it is too long and annoying to see ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just one text file. So this **dtm_text** contains the just one row and the values are the counts of the various words in the vocabulary. This is actually the **Document Term Matrix (DTM)** in **Text Classification** tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsVfLw_jYd0s"
   },
   "outputs": [],
   "source": [
    "dtm_text=text_count.toarray()   # this gives the kibnd of document term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBMKxkRxc03A"
   },
   "outputs": [],
   "source": [
    "word_index_dict=vect_count.vocabulary_  # this gives the words and their corresponding indices in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ifaYIpTUdaRY"
   },
   "outputs": [],
   "source": [
    "word_count_dict={k: dtm_text[0][v] for k, v in sorted(word_index_dict.items(), key=lambda item:item[1])}\n",
    "word_count_dict={k:v for k, v in sorted(word_count_dict.items(), key=lambda item:item[1],reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This dictionary now has the required structure. \n",
    "\n",
    "****The key is the word and the value is the count of that word in the file. Also the words are arranged in non increasing order of count.****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "h_z1rQICqRo8",
    "outputId": "e856112b-4849-4a3f-cc7f-86641a620836"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'holmes': 69,\n",
       " 'said': 57,\n",
       " 'mr': 37,\n",
       " 'man': 35,\n",
       " 'good': 26,\n",
       " 'know': 26,\n",
       " 'little': 26,\n",
       " 'room': 23,\n",
       " 'just': 22,\n",
       " 'red': 22,\n",
       " 'photograph': 21,\n",
       " 'sherlock': 20,\n",
       " 'street': 20,\n",
       " 'door': 18,\n",
       " 'majesty': 18,\n",
       " 'come': 17,\n",
       " 'did': 17,\n",
       " 'king': 17,\n",
       " 'men': 17,\n",
       " 'hand': 16,\n",
       " 'house': 16,\n",
       " 'paper': 16,\n",
       " 'right': 16,\n",
       " 'wilson': 16,\n",
       " 'matter': 15,\n",
       " 'time': 15,\n",
       " 'asked': 14,\n",
       " 'came': 14,\n",
       " 'day': 14,\n",
       " 'half': 14,\n",
       " 'heard': 14,\n",
       " 'irene': 14,\n",
       " 'left': 14,\n",
       " 'minutes': 14,\n",
       " 'quite': 14,\n",
       " 'think': 14,\n",
       " 'woman': 14,\n",
       " 'adler': 13,\n",
       " 'business': 13,\n",
       " 'eyes': 13,\n",
       " 'face': 13,\n",
       " 'morning': 13,\n",
       " 'open': 13,\n",
       " 'took': 13,\n",
       " 'headed': 12,\n",
       " 'make': 12,\n",
       " 'briony': 11,\n",
       " 'case': 11,\n",
       " 'gentleman': 11,\n",
       " 'league': 11,\n",
       " 'lodge': 11,\n",
       " 'look': 11,\n",
       " 'read': 11,\n",
       " 'seen': 11,\n",
       " 'shall': 11,\n",
       " 'small': 11,\n",
       " 'tell': 11,\n",
       " 'window': 11,\n",
       " 'work': 11,\n",
       " 'answered': 10,\n",
       " 'away': 10,\n",
       " 'cried': 10,\n",
       " 'dear': 10,\n",
       " 'friend': 10,\n",
       " 'head': 10,\n",
       " 'lady': 10,\n",
       " 'note': 10,\n",
       " 'remarked': 10,\n",
       " 'say': 10,\n",
       " 'sir': 10,\n",
       " 'watson': 10,\n",
       " 'advertisement': 9,\n",
       " 'bohemia': 9,\n",
       " 'course': 9,\n",
       " 'end': 9,\n",
       " 'hair': 9,\n",
       " 'like': 9,\n",
       " 'looked': 9,\n",
       " 'mind': 9,\n",
       " 'thought': 9,\n",
       " 'twice': 9,\n",
       " 'way': 9,\n",
       " 'able': 8,\n",
       " 'address': 8,\n",
       " 'adventure': 8,\n",
       " 'chair': 8,\n",
       " 'client': 8,\n",
       " 'clock': 8,\n",
       " 'great': 8,\n",
       " 'hands': 8,\n",
       " 'night': 8,\n",
       " 'oh': 8,\n",
       " 'pay': 8,\n",
       " 'saw': 8,\n",
       " 'simple': 8,\n",
       " 'started': 8,\n",
       " 'sure': 8,\n",
       " 'better': 7,\n",
       " 'clear': 7,\n",
       " 'doctor': 7,\n",
       " 'does': 7,\n",
       " 'doubt': 7,\n",
       " 'norton': 7,\n",
       " 'office': 7,\n",
       " 'pulled': 7,\n",
       " 'rushed': 7,\n",
       " 'sitting': 7,\n",
       " 'spaulding': 7,\n",
       " 'understand': 7,\n",
       " 'vacancy': 7,\n",
       " 'watch': 7,\n",
       " 'week': 7,\n",
       " 'wish': 7,\n",
       " 'yes': 7,\n",
       " 'baker': 6,\n",
       " 'certainly': 6,\n",
       " 'church': 6,\n",
       " 'dark': 6,\n",
       " 'evening': 6,\n",
       " 'german': 6,\n",
       " 'gutenberg': 6,\n",
       " 'hear': 6,\n",
       " 'home': 6,\n",
       " 'jabez': 6,\n",
       " 'knew': 6,\n",
       " 'life': 6,\n",
       " 'long': 6,\n",
       " 'love': 6,\n",
       " 'nature': 6,\n",
       " 'person': 6,\n",
       " 'point': 6,\n",
       " 'present': 6,\n",
       " 'project': 6,\n",
       " 'seven': 6,\n",
       " 'steps': 6,\n",
       " 'thing': 6,\n",
       " 'use': 6,\n",
       " 'visitor': 6,\n",
       " 'went': 6,\n",
       " 'written': 6,\n",
       " 'years': 6,\n",
       " 'adventures': 5,\n",
       " 'apply': 5,\n",
       " 'armchair': 5,\n",
       " 'assistant': 5,\n",
       " 'bell': 5,\n",
       " 'best': 5,\n",
       " 'cab': 5,\n",
       " 'character': 5,\n",
       " 'clergyman': 5,\n",
       " 'companion': 5,\n",
       " 'corner': 5,\n",
       " 'don': 5,\n",
       " 'double': 5,\n",
       " 'duncan': 5,\n",
       " 'ebook': 5,\n",
       " 'facts': 5,\n",
       " 'godfrey': 5,\n",
       " 'got': 5,\n",
       " 'hardly': 5,\n",
       " 'heavy': 5,\n",
       " 'help': 5,\n",
       " 'imagine': 5,\n",
       " 'instant': 5,\n",
       " 'large': 5,\n",
       " 'let': 5,\n",
       " 'looking': 5,\n",
       " 'married': 5,\n",
       " 'mask': 5,\n",
       " 'miss': 5,\n",
       " 'moment': 5,\n",
       " 'new': 5,\n",
       " 'object': 5,\n",
       " 'old': 5,\n",
       " 'past': 5,\n",
       " 'peculiar': 5,\n",
       " 'pray': 5,\n",
       " 'raise': 5,\n",
       " 'really': 5,\n",
       " 'ross': 5,\n",
       " 'round': 5,\n",
       " 'scandal': 5,\n",
       " 'serpentine': 5,\n",
       " 'soul': 5,\n",
       " 'table': 5,\n",
       " 'told': 5,\n",
       " 'wait': 5,\n",
       " 'word': 5,\n",
       " 'young': 5,\n",
       " 'account': 4,\n",
       " 'agent': 4,\n",
       " 'ago': 4,\n",
       " 'alarm': 4,\n",
       " 'appearance': 4,\n",
       " 'appeared': 4,\n",
       " 'arthur': 4,\n",
       " 'avenue': 4,\n",
       " 'began': 4,\n",
       " 'bit': 4,\n",
       " 'black': 4,\n",
       " 'bought': 4,\n",
       " 'bring': 4,\n",
       " 'brougham': 4,\n",
       " 'cases': 4,\n",
       " 'caught': 4,\n",
       " 'china': 4,\n",
       " 'comes': 4,\n",
       " 'coming': 4,\n",
       " 'conan': 4,\n",
       " 'country': 4,\n",
       " 'crime': 4,\n",
       " 'crowd': 4,\n",
       " 'deduce': 4,\n",
       " 'deep': 4,\n",
       " 'delicate': 4,\n",
       " 'doyle': 4,\n",
       " 'dress': 4,\n",
       " 'dressed': 4,\n",
       " 'drove': 4,\n",
       " 'english': 4,\n",
       " 'excuse': 4,\n",
       " 'extraordinary': 4,\n",
       " 'family': 4,\n",
       " 'far': 4,\n",
       " 'follow': 4,\n",
       " 'followed': 4,\n",
       " 'fortune': 4,\n",
       " 'forward': 4,\n",
       " 'gave': 4,\n",
       " 'given': 4,\n",
       " 'hat': 4,\n",
       " 'having': 4,\n",
       " 'hope': 4,\n",
       " 'hopes': 4,\n",
       " 'importance': 4,\n",
       " 'important': 4,\n",
       " 'information': 4,\n",
       " 'interested': 4,\n",
       " 'john': 4,\n",
       " 'landau': 4,\n",
       " 'late': 4,\n",
       " 'laughed': 4,\n",
       " 'laughing': 4,\n",
       " 'lay': 4,\n",
       " 'leave': 4,\n",
       " 'letter': 4,\n",
       " 'london': 4,\n",
       " 'lost': 4,\n",
       " 'marriage': 4,\n",
       " 'matters': 4,\n",
       " 'mean': 4,\n",
       " 'memory': 4,\n",
       " 'merely': 4,\n",
       " 'morrow': 4,\n",
       " 'near': 4,\n",
       " 'observed': 4,\n",
       " 'people': 4,\n",
       " 'position': 4,\n",
       " 'precisely': 4,\n",
       " 'pushed': 4,\n",
       " 'putting': 4,\n",
       " 'quick': 4,\n",
       " 'remarkable': 4,\n",
       " 'returned': 4,\n",
       " 'rocket': 4,\n",
       " 'save': 4,\n",
       " 'secure': 4,\n",
       " 'shouted': 4,\n",
       " 'shown': 4,\n",
       " 'singular': 4,\n",
       " 'smoke': 4,\n",
       " 'st': 4,\n",
       " 'stay': 4,\n",
       " 'stepped': 4,\n",
       " 'stood': 4,\n",
       " 'strange': 4,\n",
       " 'study': 4,\n",
       " 'suit': 4,\n",
       " 'surprise': 4,\n",
       " 'temple': 4,\n",
       " 'things': 4,\n",
       " 'throw': 4,\n",
       " 'times': 4,\n",
       " 'turn': 4,\n",
       " 'turned': 4,\n",
       " 'vincent': 4,\n",
       " 'voice': 4,\n",
       " 'von': 4,\n",
       " 'walk': 4,\n",
       " 'wanted': 4,\n",
       " 'white': 4,\n",
       " 'writing': 4,\n",
       " 'absolutely': 3,\n",
       " 'accustomed': 3,\n",
       " 'admirably': 3,\n",
       " 'age': 3,\n",
       " 'air': 3,\n",
       " 'altar': 3,\n",
       " 'attention': 3,\n",
       " 'aware': 3,\n",
       " 'bachelor': 3,\n",
       " 'bedroom': 3,\n",
       " 'begin': 3,\n",
       " 'blue': 3,\n",
       " 'bohemian': 3,\n",
       " 'broad': 3,\n",
       " 'brought': 3,\n",
       " 'brown': 3,\n",
       " 'called': 3,\n",
       " 'carriage': 3,\n",
       " 'chain': 3,\n",
       " 'chance': 3,\n",
       " 'change': 3,\n",
       " 'chest': 3,\n",
       " 'chronicle': 3,\n",
       " 'clothes': 3,\n",
       " 'coachman': 3,\n",
       " 'coat': 3,\n",
       " 'colour': 3,\n",
       " 'couch': 3,\n",
       " 'count': 3,\n",
       " 'couple': 3,\n",
       " 'court': 3,\n",
       " 'different': 3,\n",
       " 'doing': 3,\n",
       " 'drive': 3,\n",
       " 'easy': 3,\n",
       " 'engaged': 3,\n",
       " 'entered': 3,\n",
       " 'europe': 3,\n",
       " 'excellent': 3,\n",
       " 'eye': 3,\n",
       " 'fact': 3,\n",
       " 'false': 3,\n",
       " 'fashion': 3,\n",
       " 'felt': 3,\n",
       " 'figure': 3,\n",
       " 'file': 3,\n",
       " 'fortunate': 3,\n",
       " 'getting': 3,\n",
       " 'girl': 3,\n",
       " 'glad': 3,\n",
       " 'glanced': 3,\n",
       " 'glass': 3,\n",
       " 'glimpse': 3,\n",
       " 'guardsmen': 3,\n",
       " 'ha': 3,\n",
       " 'hall': 3,\n",
       " 'hard': 3,\n",
       " 'heads': 3,\n",
       " 'high': 3,\n",
       " 'honour': 3,\n",
       " 'horses': 3,\n",
       " 'hour': 3,\n",
       " 'hours': 3,\n",
       " 'hum': 3,\n",
       " 'hurried': 3,\n",
       " 'husband': 3,\n",
       " 'ii': 3,\n",
       " 'immediately': 3,\n",
       " 'instance': 3,\n",
       " 'interfere': 3,\n",
       " 'keen': 3,\n",
       " 'laid': 3,\n",
       " 'lately': 3,\n",
       " 'lawyer': 3,\n",
       " 'legal': 3,\n",
       " 'letters': 3,\n",
       " 'likely': 3,\n",
       " 'listened': 3,\n",
       " 'lit': 3,\n",
       " 'manner': 3,\n",
       " 'mews': 3,\n",
       " 'money': 3,\n",
       " 'monica': 3,\n",
       " 'murmured': 3,\n",
       " 'mystery': 3,\n",
       " 'nominal': 3,\n",
       " 'orange': 3,\n",
       " 'outside': 3,\n",
       " 'paced': 3,\n",
       " 'pair': 3,\n",
       " 'pocket': 3,\n",
       " 'pope': 3,\n",
       " 'pounds': 3,\n",
       " 'powers': 3,\n",
       " 'practice': 3,\n",
       " 'private': 3,\n",
       " 'problem': 3,\n",
       " 'pull': 3,\n",
       " 'purely': 3,\n",
       " 'question': 3,\n",
       " 'questioning': 3,\n",
       " 'reached': 3,\n",
       " 'ready': 3,\n",
       " 'reasoner': 3,\n",
       " 'reasoning': 3,\n",
       " 'received': 3,\n",
       " 'rich': 3,\n",
       " 'road': 3,\n",
       " 'rose': 3,\n",
       " 'running': 3,\n",
       " 'sat': 3,\n",
       " 'scene': 3,\n",
       " 'seized': 3,\n",
       " 'seldom': 3,\n",
       " 'sent': 3,\n",
       " 'seriously': 3,\n",
       " 'servant': 3,\n",
       " 'set': 3,\n",
       " 'sharp': 3,\n",
       " 'sheet': 3,\n",
       " 'size': 3,\n",
       " 'snuff': 3,\n",
       " 'soon': 3,\n",
       " 'sound': 3,\n",
       " 'sovereign': 3,\n",
       " 'spoke': 3,\n",
       " 'square': 3,\n",
       " 'station': 3,\n",
       " 'step': 3,\n",
       " 'strong': 3,\n",
       " 'successful': 3,\n",
       " 'suddenly': 3,\n",
       " 'suited': 3,\n",
       " 'taken': 3,\n",
       " 'taking': 3,\n",
       " 'threw': 3,\n",
       " 'title': 3,\n",
       " 'tore': 3,\n",
       " 'true': 3,\n",
       " 'trust': 3,\n",
       " 'used': 3,\n",
       " 'waiting': 3,\n",
       " 'walked': 3,\n",
       " 'weeks': 3,\n",
       " 'wheels': 3,\n",
       " 'willing': 3,\n",
       " 'women': 3,\n",
       " 'world': 3,\n",
       " 'worth': 3,\n",
       " 'wrote': 3,\n",
       " 'year': 3,\n",
       " 'youth': 3,\n",
       " '15': 2,\n",
       " '1890': 2,\n",
       " 'adjusted': 2,\n",
       " 'admirable': 2,\n",
       " 'admit': 2,\n",
       " 'advantage': 2,\n",
       " 'affair': 2,\n",
       " 'afternoon': 2,\n",
       " 'ah': 2,\n",
       " 'akin': 2,\n",
       " 'altogether': 2,\n",
       " 'american': 2,\n",
       " 'announcement': 2,\n",
       " 'associated': 2,\n",
       " 'attempt': 2,\n",
       " 'attempts': 2,\n",
       " 'bad': 2,\n",
       " 'baggy': 2,\n",
       " 'balancing': 2,\n",
       " 'beaten': 2,\n",
       " 'beautiful': 2,\n",
       " 'belief': 2,\n",
       " 'believe': 2,\n",
       " 'beryl': 2,\n",
       " 'billet': 2,\n",
       " 'blazing': 2,\n",
       " 'bore': 2,\n",
       " 'bowed': 2,\n",
       " 'britannica': 2,\n",
       " 'broke': 2,\n",
       " 'cabinet': 2,\n",
       " 'cabman': 2,\n",
       " 'cardboard': 2,\n",
       " 'care': 2,\n",
       " 'carried': 2,\n",
       " 'carry': 2,\n",
       " 'cause': 2,\n",
       " 'chagrin': 2,\n",
       " 'chamber': 2,\n",
       " 'chambers': 2,\n",
       " 'changed': 2,\n",
       " 'check': 2,\n",
       " 'choked': 2,\n",
       " 'chuckled': 2,\n",
       " 'cigarette': 2,\n",
       " 'cigars': 2,\n",
       " 'city': 2,\n",
       " 'clean': 2,\n",
       " 'clearing': 2,\n",
       " 'cloak': 2,\n",
       " 'close': 2,\n",
       " 'closed': 2,\n",
       " 'closely': 2,\n",
       " 'cold': 2,\n",
       " 'coloured': 2,\n",
       " 'column': 2,\n",
       " 'committed': 2,\n",
       " 'company': 2,\n",
       " 'compelled': 2,\n",
       " 'complete': 2,\n",
       " 'confined': 2,\n",
       " 'consult': 2,\n",
       " 'continue': 2,\n",
       " 'continued': 2,\n",
       " 'contrary': 2,\n",
       " 'copper': 2,\n",
       " 'copyright': 2,\n",
       " 'costume': 2,\n",
       " 'crimes': 2,\n",
       " 'crown': 2,\n",
       " 'dashed': 2,\n",
       " 'data': 2,\n",
       " 'date': 2,\n",
       " 'days': 2,\n",
       " 'deal': 2,\n",
       " 'deduction': 2,\n",
       " 'deeply': 2,\n",
       " 'delicacy': 2,\n",
       " 'desire': 2,\n",
       " 'determined': 2,\n",
       " 'direction': 2,\n",
       " 'directions': 2,\n",
       " 'dozen': 2,\n",
       " 'dr': 2,\n",
       " 'drawing': 2,\n",
       " 'drew': 2,\n",
       " 'drop': 2,\n",
       " 'dropped': 2,\n",
       " 'drug': 2,\n",
       " 'eagerly': 2,\n",
       " 'ear': 2,\n",
       " 'earn': 2,\n",
       " 'easily': 2,\n",
       " 'ebooks': 2,\n",
       " 'edgeware': 2,\n",
       " 'elderly': 2,\n",
       " 'eligible': 2,\n",
       " 'emerged': 2,\n",
       " 'emotion': 2,\n",
       " 'employed': 2,\n",
       " 'encyclopaedia': 2,\n",
       " 'energetic': 2,\n",
       " 'england': 2,\n",
       " 'enter': 2,\n",
       " 'entirely': 2,\n",
       " 'especially': 2,\n",
       " 'events': 2,\n",
       " 'evidently': 2,\n",
       " 'examined': 2,\n",
       " 'example': 2,\n",
       " 'expected': 2,\n",
       " 'experience': 2,\n",
       " 'expression': 2,\n",
       " 'extreme': 2,\n",
       " 'ezekiah': 2,\n",
       " 'faced': 2,\n",
       " 'factor': 2,\n",
       " 'fail': 2,\n",
       " 'fare': 2,\n",
       " 'fault': 2,\n",
       " 'fear': 2,\n",
       " 'features': 2,\n",
       " 'fell': 2,\n",
       " 'fellow': 2,\n",
       " 'field': 2,\n",
       " 'fierce': 2,\n",
       " 'fiery': 2,\n",
       " 'filled': 2,\n",
       " 'fine': 2,\n",
       " 'finger': 2,\n",
       " 'fishes': 2,\n",
       " 'flame': 2,\n",
       " 'fleet': 2,\n",
       " 'flight': 2,\n",
       " 'folk': 2,\n",
       " 'following': 2,\n",
       " 'foolscap': 2,\n",
       " 'forefinger': 2,\n",
       " 'forehead': 2,\n",
       " 'formidable': 2,\n",
       " 'freemasonry': 2,\n",
       " 'frequently': 2,\n",
       " 'fund': 2,\n",
       " 'future': 2,\n",
       " 'gain': 2,\n",
       " 'garden': 2,\n",
       " 'general': 2,\n",
       " 'gentlemen': 2,\n",
       " 'glance': 2,\n",
       " 'going': 2,\n",
       " 'gold': 2,\n",
       " 'gone': 2,\n",
       " 'greeting': 2,\n",
       " 'grinder': 2,\n",
       " 'groom': 2,\n",
       " 'ground': 2,\n",
       " 'habit': 2,\n",
       " 'habits': 2,\n",
       " 'hadn': 2,\n",
       " 'halfway': 2,\n",
       " 'handsome': 2,\n",
       " 'hanging': 2,\n",
       " 'harness': 2,\n",
       " 'header': 2,\n",
       " 'heartily': 2,\n",
       " 'held': 2,\n",
       " 'hereditary': 2,\n",
       " 'hopkins': 2,\n",
       " 'hot': 2,\n",
       " 'iii': 2,\n",
       " 'ill': 2,\n",
       " 'immense': 2,\n",
       " 'inches': 2,\n",
       " 'incisive': 2,\n",
       " 'indicated': 2,\n",
       " 'influence': 2,\n",
       " 'injured': 2,\n",
       " 'injuring': 2,\n",
       " 'ink': 2,\n",
       " 'inquiry': 2,\n",
       " 'inside': 2,\n",
       " 'instead': 2,\n",
       " 'intention': 2,\n",
       " 'interesting': 2,\n",
       " 'kindly': 2,\n",
       " 'kingdom': 2,\n",
       " 'knot': 2,\n",
       " 'kramm': 2,\n",
       " 'labour': 2,\n",
       " 'lamps': 2,\n",
       " 'landlady': 2,\n",
       " 'lane': 2,\n",
       " 'larger': 2,\n",
       " 'later': 2,\n",
       " 'laws': 2,\n",
       " 'lead': 2,\n",
       " 'leather': 2,\n",
       " 'led': 2,\n",
       " 'level': 2,\n",
       " 'lie': 2,\n",
       " 'light': 2,\n",
       " 'lighting': 2,\n",
       " 'lip': 2,\n",
       " 'living': 2,\n",
       " 'll': 2,\n",
       " 'locked': 2,\n",
       " 'lose': 2,\n",
       " 'lounged': 2,\n",
       " 'loungers': 2,\n",
       " 'lounging': 2,\n",
       " 'maid': 2,\n",
       " 'male': 2,\n",
       " 'manager': 2,\n",
       " 'manual': 2,\n",
       " 'march': 2,\n",
       " 'mark': 2,\n",
       " 'marry': 2,\n",
       " 'mary': 2,\n",
       " 'member': 2,\n",
       " 'mistake': 2,\n",
       " 'mistress': 2,\n",
       " 'monday': 2,\n",
       " 'months': 2,\n",
       " 'mysteries': 2,\n",
       " 'narrative': 2,\n",
       " 'nearly': 2,\n",
       " 'need': 2,\n",
       " 'neighbourhood': 2,\n",
       " 'neutral': 2,\n",
       " 'news': 2,\n",
       " 'nice': 2,\n",
       " 'noble': 2,\n",
       " 'number': 2,\n",
       " 'observe': 2,\n",
       " 'observing': 2,\n",
       " 'obvious': 2,\n",
       " 'occasionally': 2,\n",
       " 'occur': 2,\n",
       " 'opened': 2,\n",
       " 'opening': 2,\n",
       " 'order': 2,\n",
       " 'ormstein': 2,\n",
       " 'ostlers': 2,\n",
       " 'pacing': 2,\n",
       " 'paint': 2,\n",
       " 'palm': 2,\n",
       " 'panel': 2,\n",
       " 'papers': 2,\n",
       " 'particularly': 2,\n",
       " 'passage': 2,\n",
       " 'passed': 2,\n",
       " 'passing': 2,\n",
       " 'paused': 2,\n",
       " 'pawnbroker': 2,\n",
       " 'perfectly': 2,\n",
       " 'pink': 2,\n",
       " 'pity': 2,\n",
       " 'plan': 2,\n",
       " 'plans': 2,\n",
       " 'pockets': 2,\n",
       " 'pooh': 2,\n",
       " 'poor': 2,\n",
       " 'possibility': 2,\n",
       " 'possible': 2,\n",
       " 'post': 2,\n",
       " 'power': 2,\n",
       " 'precaution': 2,\n",
       " 'preposterous': 2,\n",
       " 'presented': 2,\n",
       " 'press': 2,\n",
       " 'pretty': 2,\n",
       " 'probably': 2,\n",
       " 'process': 2,\n",
       " 'promises': 2,\n",
       " 'prompt': 2,\n",
       " 'prove': 2,\n",
       " 'quarter': 2,\n",
       " 'quarters': 2,\n",
       " 'queen': 2,\n",
       " 'quest': 2,\n",
       " 'quiet': 2,\n",
       " 'quietly': 2,\n",
       " 'ran': 2,\n",
       " 'ransacked': 2,\n",
       " 'reach': 2,\n",
       " 'real': 2,\n",
       " 'reason': 2,\n",
       " 'reigning': 2,\n",
       " 'rely': 2,\n",
       " 'remain': 2,\n",
       " 'remarkably': 2,\n",
       " 'remember': 2,\n",
       " 'remove': 2,\n",
       " 'resolute': 2,\n",
       " 'rest': 2,\n",
       " 'returns': 2,\n",
       " 'ring': 2,\n",
       " 'rooms': 2,\n",
       " 'royal': 2,\n",
       " 'ruin': 2,\n",
       " 'rush': 2,\n",
       " 'says': 2,\n",
       " 'scissors': 2,\n",
       " 'send': 2,\n",
       " 'services': 2,\n",
       " 'shade': 2,\n",
       " 'shelves': 2,\n",
       " 'shoulders': 2,\n",
       " 'shouting': 2,\n",
       " 'showing': 2,\n",
       " 'shut': 2,\n",
       " 'signal': 2,\n",
       " 'silence': 2,\n",
       " 'single': 2,\n",
       " 'sings': 2,\n",
       " 'situation': 2,\n",
       " 'sliding': 2,\n",
       " 'slight': 2,\n",
       " 'slow': 2,\n",
       " 'slowly': 2,\n",
       " 'smile': 2,\n",
       " 'sorry': 2,\n",
       " 'sort': 2,\n",
       " 'spare': 2,\n",
       " 'spirits': 2,\n",
       " 'spoken': 2,\n",
       " 'sprang': 2,\n",
       " 'stage': 2,\n",
       " 'stands': 2,\n",
       " 'steel': 2,\n",
       " 'stolen': 2,\n",
       " 'story': 2,\n",
       " 'stout': 2,\n",
       " 'streets': 2,\n",
       " 'stretched': 2,\n",
       " 'strict': 2,\n",
       " 'struck': 2,\n",
       " 'subject': 2,\n",
       " 'success': 2,\n",
       " 'swiftly': 2,\n",
       " 'sympathy': 2,\n",
       " 'telling': 2,\n",
       " 'thank': 2,\n",
       " 'theories': 2,\n",
       " 'thousands': 2,\n",
       " 'thursday': 2,\n",
       " 'tie': 2,\n",
       " 'tint': 2,\n",
       " 'trained': 2,\n",
       " 'trick': 2,\n",
       " 'trousers': 2,\n",
       " 'trustees': 2,\n",
       " 'ulster': 2,\n",
       " 'unique': 2,\n",
       " 'usual': 2,\n",
       " 'vacancies': 2,\n",
       " 'view': 2,\n",
       " 'volume': 2,\n",
       " 'want': 2,\n",
       " 'warsaw': 2,\n",
       " 'watched': 2,\n",
       " 'watching': 2,\n",
       " 'waylaid': 2,\n",
       " 'weapon': 2,\n",
       " 'wear': 2,\n",
       " 'windows': 2,\n",
       " 'won': 2,\n",
       " 'wonder': 2,\n",
       " 'wore': 2,\n",
       " 'wrinkled': 2,\n",
       " 'wrist': 2,\n",
       " '12': 1,\n",
       " '1661': 1,\n",
       " '1858': 1,\n",
       " '1888': 1,\n",
       " '1971': 1,\n",
       " '1999': 1,\n",
       " '2002': 1,\n",
       " '27': 1,\n",
       " '29': 1,\n",
       " 'abandoned': 1,\n",
       " 'abbots': 1,\n",
       " 'abhorrent': 1,\n",
       " 'abruptly': 1,\n",
       " 'absolute': 1,\n",
       " 'absorb': 1,\n",
       " 'accent': 1,\n",
       " 'accomplice': 1,\n",
       " 'accomplished': 1,\n",
       " 'acknowledges': 1,\n",
       " 'acquaintance': 1,\n",
       " 'action': 1,\n",
       " 'actions': 1,\n",
       " 'active': 1,\n",
       " 'activity': 1,\n",
       " 'actor': 1,\n",
       " 'actress': 1,\n",
       " 'acute': 1,\n",
       " 'added': 1,\n",
       " 'addition': 1,\n",
       " 'additional': 1,\n",
       " 'addressing': 1,\n",
       " 'adopted': 1,\n",
       " 'advantages': 1,\n",
       " 'adventuress': 1,\n",
       " 'advise': 1,\n",
       " 'affairs': 1,\n",
       " 'affect': 1,\n",
       " 'afraid': 1,\n",
       " 'agitation': 1,\n",
       " 'aisle': 1,\n",
       " 'albert': 1,\n",
       " 'aloud': 1,\n",
       " 'alternating': 1,\n",
       " 'amazement': 1,\n",
       " 'amazing': 1,\n",
       " 'ambition': 1,\n",
       " 'amiable': 1,\n",
       " 'amiss': 1,\n",
       " 'animated': 1,\n",
       " 'annoyance': 1,\n",
       " 'answer': 1,\n",
       " 'antagonist': 1,\n",
       " 'anxiety': 1,\n",
       " 'anxious': 1,\n",
       " 'apart': 1,\n",
       " 'apiece': 1,\n",
       " 'apology': 1,\n",
       " 'apparent': 1,\n",
       " 'apparently': 1,\n",
       " 'appears': 1,\n",
       " 'applying': 1,\n",
       " 'april': 1,\n",
       " 'aquiline': 1,\n",
       " 'arc': 1,\n",
       " 'archery': 1,\n",
       " 'architecture': 1,\n",
       " 'arm': 1,\n",
       " 'armour': 1,\n",
       " 'arms': 1,\n",
       " 'arnsworth': 1,\n",
       " 'arranged': 1,\n",
       " 'arrangements': 1,\n",
       " 'arrest': 1,\n",
       " 'arrived': 1,\n",
       " 'ascii': 1,\n",
       " 'ashamed': 1,\n",
       " 'ask': 1,\n",
       " 'asks': 1,\n",
       " 'assistants': 1,\n",
       " 'assisting': 1,\n",
       " 'assumed': 1,\n",
       " 'assuring': 1,\n",
       " 'astrakhan': 1,\n",
       " 'atkinson': 1,\n",
       " 'attend': 1,\n",
       " 'attica': 1,\n",
       " 'attitude': 1,\n",
       " 'attracted': 1,\n",
       " 'august': 1,\n",
       " 'authenticity': 1,\n",
       " 'author': 1,\n",
       " 'authoritative': 1,\n",
       " 'autumn': 1,\n",
       " 'avail': 1,\n",
       " 'average': 1,\n",
       " 'averse': 1,\n",
       " 'awaiting': 1,\n",
       " 'awkward': 1,\n",
       " 'baby': 1,\n",
       " 'backward': 1,\n",
       " 'bade': 1,\n",
       " 'baffled': 1,\n",
       " 'bag': 1,\n",
       " 'balanced': 1,\n",
       " 'band': 1,\n",
       " 'bands': 1,\n",
       " 'banker': 1,\n",
       " 'barbaric': 1,\n",
       " 'barrow': 1,\n",
       " 'bashful': 1,\n",
       " 'beamed': 1,\n",
       " 'bear': 1,\n",
       " 'beauties': 1,\n",
       " 'beautifully': 1,\n",
       " 'bedtime': 1,\n",
       " 'beeches': 1,\n",
       " 'beef': 1,\n",
       " 'beer': 1,\n",
       " 'begins': 1,\n",
       " 'benefactor': 1,\n",
       " 'benevolent': 1,\n",
       " 'bequest': 1,\n",
       " 'berths': 1,\n",
       " 'betrayed': 1,\n",
       " 'betrothal': 1,\n",
       " 'bijou': 1,\n",
       " 'binding': 1,\n",
       " 'biographies': 1,\n",
       " 'biography': 1,\n",
       " 'bizarre': 1,\n",
       " 'blackest': 1,\n",
       " 'blackmailing': 1,\n",
       " 'blanche': 1,\n",
       " 'blind': 1,\n",
       " 'blinds': 1,\n",
       " 'blood': 1,\n",
       " 'blotting': 1,\n",
       " 'blow': 1,\n",
       " 'bob': 1,\n",
       " 'body': 1,\n",
       " 'bonnet': 1,\n",
       " 'book': 1,\n",
       " 'books': 1,\n",
       " 'boot': 1,\n",
       " 'boots': 1,\n",
       " 'born': 1,\n",
       " 'borne': 1,\n",
       " 'boscombe': 1,\n",
       " 'boswell': 1,\n",
       " 'bottle': 1,\n",
       " 'bound': 1,\n",
       " 'box': 1,\n",
       " 'boy': 1,\n",
       " 'brassy': 1,\n",
       " 'brave': 1,\n",
       " 'breaking': 1,\n",
       " 'breaks': 1,\n",
       " 'breasted': 1,\n",
       " 'breastpin': 1,\n",
       " 'breathing': 1,\n",
       " 'brick': 1,\n",
       " 'bride': 1,\n",
       " 'bridegroom': 1,\n",
       " 'briefly': 1,\n",
       " 'bright': 1,\n",
       " 'brilliantly': 1,\n",
       " 'brimmed': 1,\n",
       " 'british': 1,\n",
       " 'broken': 1,\n",
       " 'brooch': 1,\n",
       " 'brothers': 1,\n",
       " 'brushed': 1,\n",
       " 'buckles': 1,\n",
       " 'budge': 1,\n",
       " 'building': 1,\n",
       " 'built': 1,\n",
       " 'bulge': 1,\n",
       " 'burglars': 1,\n",
       " 'burgled': 1,\n",
       " 'buried': 1,\n",
       " 'burned': 1,\n",
       " 'busier': 1,\n",
       " 'busy': 1,\n",
       " 'butted': 1,\n",
       " 'buttoned': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP TEN WORDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "vdZJpJwgv1gC",
    "outputId": "00f2dcb9-0aaf-436b-ae4b-c468ca6d2327"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('holmes', 69),\n",
       " ('said', 57),\n",
       " ('mr', 37),\n",
       " ('man', 35),\n",
       " ('good', 26),\n",
       " ('know', 26),\n",
       " ('little', 26),\n",
       " ('room', 23),\n",
       " ('just', 22),\n",
       " ('red', 22)]"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_list=list(word_count_dict.items())\n",
    "top_ten_words=sorted_list[:10]  # sorted_lsit is the list of tuples for which the individual task is the n\n",
    "top_ten_words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1ypWKqXyKwi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "GoIbibo Internship Assignment-Approach2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
